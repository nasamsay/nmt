{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiC75uo6u_Of"
      },
      "source": [
        "##Machine Translation Using a Seq2Seq Architecture\n",
        "© 2023, Zaka AI, Inc. All Rights Reserved.\n",
        "\n",
        "---\n",
        "The goal of this colab is to get you more familiar with the Seq2Seq models and their challenges. For this reason, you will be working on machine translation problem where we would have a sentence as input (in english), and the output is gonna be the translated sentence (in french). So just like what happens with Google Translate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeK4LPupvg_c"
      },
      "source": [
        "**Just to give you a heads up:** We won't be having a model performing like Google translate, but at least we will have an idea about how Google Translate works and the challenges that exist with a translation problem.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBTvDTzBv293"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_j1ZzS3v6N3"
      },
      "source": [
        "We start by importing numpy and pandas and then we can add the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0IARXAX1e1m",
        "outputId": "66a3bff4-04c1-4928-db3b-22735f805b7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Nasam\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAcLqZ7uv-SJ"
      },
      "source": [
        "We clone the github repository where our data exists. Here is the github link: https://github.com/zaka-ai/machine_learning_certification/tree/main/Challenge%207 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3hLN42axOjn"
      },
      "source": [
        "## Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-M7cFxTPpqy",
        "outputId": "53df8420-f7c0-40a8-b43e-b8b09240d47c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "c:\\Users\\Nasam\\Downloads\\machine_learning_certification\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "!git clone https://github.com/zaka-ai/machine_learning_certification.git\n",
        "\n",
        "%cd machine_learning_certification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPr0N8cwGAv"
      },
      "source": [
        "We read the english sentences in a dataframe named \"english\", and the french sentences in a dataframe named \"french\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kFj8gkP01lGT",
        "outputId": "0e8fcf62-916f-4608-b20c-5f6df142ecec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-575d946f-ed7b-40f7-835b-dd57826e8018\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-575d946f-ed7b-40f7-835b-dd57826e8018')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-575d946f-ed7b-40f7-835b-dd57826e8018 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-575d946f-ed7b-40f7-835b-dd57826e8018');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                        en_sentences\n",
              "0  new jersey is sometimes quiet during autumn , ...\n",
              "1  the united states is usually chilly during jul...\n",
              "2  california is usually quiet during march , and...\n",
              "3  the united states is sometimes mild during jun...\n",
              "4  your least liked fruit is the grape , but my l..."
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Test Your Zaka (English)\n",
        "english = pd.read_csv('/content/machine_learning_certification/Challenge 7/en.csv', names=['en_sentences'], header=None)\n",
        "english.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P4A7ZKt32A7s",
        "outputId": "7d210e37-a739-4de7-ad33-7d5936deb276"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea8d6b36-bb51-4ade-a7aa-ac1cd0d792a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fr_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea8d6b36-bb51-4ade-a7aa-ac1cd0d792a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea8d6b36-bb51-4ade-a7aa-ac1cd0d792a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea8d6b36-bb51-4ade-a7aa-ac1cd0d792a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                        fr_sentences\n",
              "0  new jersey est parfois calme pendant l' automn...\n",
              "1  les états-unis est généralement froid en juill...\n",
              "2  california est généralement calme en mars , et...\n",
              "3  les états-unis est parfois légère en juin , et...\n",
              "4  votre moins aimé fruit est le raisin , mais mo..."
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Test Your Zaka (French)\n",
        "french = pd.read_csv('/content/machine_learning_certification/Challenge 7/fr.csv', names=['fr_sentences'], header=None)\n",
        "french.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr8OO1OhwSp4"
      },
      "source": [
        "**How many sentences does each of the files contain?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhWJP-b02HKq",
        "outputId": "5662f895-2226-401c-c9c4-21f97c5c2a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of english sentences: 137860\n",
            "number of french sentences: 137860\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "print(\"number of english sentences:\", english.shape[0])\n",
        "print('number of french sentences:', french.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITGJN5tIwkDO"
      },
      "source": [
        "Now let us concatenate the 2 dataframes into one dataframe that we call **df** where one column has the english senetnces and the other has the french sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-ZXxahsB2njn",
        "outputId": "bec85bde-5584-4b4a-c21a-9b4060fb001d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da60db75-46b4-477e-906d-0291387d1f71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_sentences</th>\n",
              "      <th>fr_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da60db75-46b4-477e-906d-0291387d1f71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da60db75-46b4-477e-906d-0291387d1f71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da60db75-46b4-477e-906d-0291387d1f71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                        en_sentences  \\\n",
              "0  new jersey is sometimes quiet during autumn , ...   \n",
              "1  the united states is usually chilly during jul...   \n",
              "2  california is usually quiet during march , and...   \n",
              "3  the united states is sometimes mild during jun...   \n",
              "4  your least liked fruit is the grape , but my l...   \n",
              "\n",
              "                                        fr_sentences  \n",
              "0  new jersey est parfois calme pendant l' automn...  \n",
              "1  les états-unis est généralement froid en juill...  \n",
              "2  california est généralement calme en mars , et...  \n",
              "3  les états-unis est parfois légère en juin , et...  \n",
              "4  votre moins aimé fruit est le raisin , mais mo...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "df = pd.concat([english, french], axis = 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAr_caXkwwE7"
      },
      "source": [
        "Let's name the columns as **English** and **French** so that we access them easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eOHiQDXx3jFS",
        "outputId": "21aaf067-1b04-4751-8b51-68deaf4a32b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56beaaba-a516-4e43-8464-6c18b30e4346\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56beaaba-a516-4e43-8464-6c18b30e4346')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56beaaba-a516-4e43-8464-6c18b30e4346 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56beaaba-a516-4e43-8464-6c18b30e4346');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             English  \\\n",
              "0  new jersey is sometimes quiet during autumn , ...   \n",
              "1  the united states is usually chilly during jul...   \n",
              "2  california is usually quiet during march , and...   \n",
              "3  the united states is sometimes mild during jun...   \n",
              "4  your least liked fruit is the grape , but my l...   \n",
              "\n",
              "                                              French  \n",
              "0  new jersey est parfois calme pendant l' automn...  \n",
              "1  les états-unis est généralement froid en juill...  \n",
              "2  california est généralement calme en mars , et...  \n",
              "3  les états-unis est parfois légère en juin , et...  \n",
              "4  votre moins aimé fruit est le raisin , mais mo...  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "df.rename(columns={'en_sentences':'English', 'fr_sentences':'French'}, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xc1TsEHw9yC"
      },
      "source": [
        "Pick a sentence and print it in both languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuRVWch23ujo",
        "outputId": "58164150-d194-4d3a-d4b6-157ee02fc688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the united states is sometimes mild during june , and it is cold in september .\n",
            "les états-unis est parfois légère en juin , et il fait froid en septembre .\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "print(df.loc[3, 'English'])\n",
        "print(df.loc[3, 'French'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQjXYP1txFCi"
      },
      "source": [
        "##Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgz6jIoVxHUF"
      },
      "source": [
        "The data that we have is almost clean as we can see, we just need to remove the punctuations inside of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YYOt5QftcFI"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~\")\n",
        "    return text.translate(translator)\n",
        "\n",
        "df_clean = df.applymap(remove_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C1qsC9LxZPb"
      },
      "source": [
        "Make sure that the punctuation is removed by printing the example that you printed earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T80tiWxe84G7",
        "outputId": "d6b93c28-523c-48a9-a94e-0fc62472d04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the united states is sometimes mild during june  and it is cold in september \n",
            "les étatsunis est parfois légère en juin  et il fait froid en septembre \n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "print(df_clean.loc[3, 'English'])\n",
        "print(df_clean.loc[3, 'French'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuFNjoBAx4oN"
      },
      "source": [
        "##Exploring the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATfefzPExi2k"
      },
      "source": [
        "Add a column **ENG Length** to the dataset that shows how many words does a sentence contain, and do the same for french in a column called **FR Length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dakeo81s352S"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "df_clean['ENG Length'] = df_clean['English'].str.strip().apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49keasjaPaaK"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "df_clean['FR Length'] = df_clean['French'].str.strip().apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjQLW0K5xwx1"
      },
      "source": [
        "Visualize the distribution of the lengths of english sentences and french sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_q_UIMJ09L24",
        "outputId": "eccce892-f07a-4989-ed2f-14d114101808"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "plt.hist(df_clean['ENG Length'], rwidth=0.95)\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of English Sentence Length')\n",
        "plt.xticks(range(min(df_clean['ENG Length']), max(df_clean['ENG Length'])+1, 2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TSn4L7kW9R7g",
        "outputId": "fb1681da-c2ba-4db5-bd6b-9ce70d7ed291"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "plt.hist(df_clean['FR Length'], rwidth=0.95)\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of French Sentence Length')\n",
        "plt.xticks(range(min(df_clean['FR Length']), max(df_clean['FR Length']+1), 2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDXb2d9ix9DV"
      },
      "source": [
        "Get the maximum length of an english sentence and the maximum length of a french sentence. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpnBB04U_lHd",
        "outputId": "f5334c5b-baa0-4398-bb4f-7bd3ea2fa41c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum length of an English sentence: 15\n",
            "Maximum length of a French sentence: 21\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "max_eng_length = df_clean['ENG Length'].max()\n",
        "max_fr_length = df_clean['FR Length'].max()\n",
        "\n",
        "print('Maximum length of an English sentence:', max_eng_length)\n",
        "print('Maximum length of a French sentence:', max_fr_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4s-spsRyGJv"
      },
      "source": [
        "##Preprocessing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ZmIT2GyJMU"
      },
      "source": [
        "In order for the data to be fed to the model, it has to be tokenized and padded. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0r9z-eErm9H"
      },
      "source": [
        "####Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5L_zkhfyQuX"
      },
      "source": [
        "**To tokenize english and french sentences, we can use only one tokenizer. True or False?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z0ZcNOeyauD"
      },
      "source": [
        "It's generally a good practice to use language-specific tokenizers for each language to avoid any mistakes related to the grammer for example. However, True as long as the both languages words are saperated by spaces or the same approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "814mKDFiymcY"
      },
      "source": [
        "Tokenize the sentences that we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMTD6Oe1UDTj"
      },
      "outputs": [],
      "source": [
        "df['English']=df['English'].apply(lambda x: 'ST '+x.strip().lower()+' EN')\n",
        "df['French']=df['French'].apply(lambda x: 'ST '+x.strip().lower()+' EN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiXlciqFuQzW"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# English tokenizer\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(df['English'].values)\n",
        "eng_seq = eng_tokenizer.texts_to_sequences(df['English'].values)\n",
        "\n",
        "# French tokenizer\n",
        "fr_tokenizer = Tokenizer()\n",
        "fr_tokenizer.fit_on_texts(df['French'].values)\n",
        "fr_seq = fr_tokenizer.texts_to_sequences(df['French'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUN01jDXys9B"
      },
      "source": [
        "**How many unique words do we have in english and in french?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WahkdzKvIlO",
        "outputId": "e405c245-3100-4474-e022-21761ee33d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique English words: 202\n",
            "Number of unique French words: 346\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "num_eng_words=len(eng_tokenizer.word_index)+1\n",
        "num_fr_words=len(fr_tokenizer.word_index)+1\n",
        "\n",
        "print('Number of unique English words:', num_eng_words)\n",
        "print('Number of unique French words:', num_fr_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0C2RJjArtJd"
      },
      "source": [
        "####Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXdTXMo5y8oB"
      },
      "source": [
        "**What should be the length of the sequences that we have after padding?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wtHQsgXzImq"
      },
      "source": [
        "The max length detected in the dataset which is 21 for French and 15 for English. Then, 2 is added for the \"ST\" start and \"EN\" end char."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRXayRzVzQD4"
      },
      "source": [
        "Perform padding on the sequences that we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNdO9EZrxvmN"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "eng_pad_seq = pad_sequences(eng_seq, maxlen=max_eng_length+2, padding='post')\n",
        "fr_pad_seq = pad_sequences(fr_seq, maxlen=max_fr_length+2, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxvvVU3ezUHR"
      },
      "source": [
        "##Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEKujJUEzVux"
      },
      "source": [
        "After preprrocessing the data, we can build our model. Start by building a baseline architecture relying on one directional RNNs, LSTMs, or GRUs. It will be good to lookup how to build Seq2Seq models, there are some new layers that will help you like RepeatVector and TimeDistributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmEwaLUFpwF7"
      },
      "outputs": [],
      "source": [
        "fr_pad_seq_noST = np.roll(fr_pad_seq, shift=-1, axis=-1)\n",
        "fr_pad_seq_noST[:,-1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBwu3o3dgvic"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "E_input = Input(shape=(max_eng_length+2,))                               \n",
        "E_embedding  = Embedding(input_dim=num_eng_words, output_dim=50)(E_input) \n",
        "_, Eh, Ec = LSTM(units=512, return_state=True)(E_embedding)       \n",
        "\n",
        "# Decoder layer definitions\n",
        "decoder_embedding = Embedding(input_dim=num_fr_words, output_dim=50)\n",
        "decoder_lstm = LSTM(512, return_sequences=True, return_state=True)\n",
        "decoder_dense = Dense(num_fr_words, activation='softmax')\n",
        "\n",
        "# Decoder in train mode\n",
        "D_input = Input(shape=(max_fr_length+2,))                         \n",
        "D_embedding  = decoder_embedding(D_input)                                            \n",
        "D_lstm, _, _ = decoder_lstm(D_embedding , initial_state=[Eh, Ec]) #Eh and Ec are the final hidden state and cell state of the encoder           \n",
        "D_output = decoder_dense(D_lstm)                                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP10HtNBzpT0"
      },
      "source": [
        "Compile and train the model. \n",
        "**FYI:** While specifying the architecture of your model and the number of epochs for training, keeep in your mind that your model might take A LOT of time to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWw4nBNIFp9D",
        "outputId": "f0bcb439-f766-420f-cdd0-ff17762060bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 17)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 17, 50)       10100       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 23, 50)       17300       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 512),        1153024     ['embedding[0][0]']              \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 23, 512),    1153024     ['embedding_1[0][0]',            \n",
            "                                 (None, 512),                     'lstm[0][1]',                   \n",
            "                                 (None, 512)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 23, 346)      177498      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,510,946\n",
            "Trainable params: 2,510,946\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "model = tf.keras.Model(inputs=[E_input, D_input], outputs=D_output)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4326QEEiqM8I",
        "outputId": "37d0545f-e3ea-4434-e5f9-bb32598187d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "108/108 [==============================] - 27s 164ms/step - loss: 2.6263 - sparse_categorical_accuracy: 0.4781 - val_loss: 1.8644 - val_sparse_categorical_accuracy: 0.5825\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 13s 119ms/step - loss: 1.3298 - sparse_categorical_accuracy: 0.6567 - val_loss: 0.9350 - val_sparse_categorical_accuracy: 0.7293\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 12s 114ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.7816\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 13s 117ms/step - loss: 0.6034 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.5600 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 13s 122ms/step - loss: 0.5352 - sparse_categorical_accuracy: 0.8140 - val_loss: 0.5086 - val_sparse_categorical_accuracy: 0.8240\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 13s 121ms/step - loss: 0.5485 - sparse_categorical_accuracy: 0.8123 - val_loss: 0.4886 - val_sparse_categorical_accuracy: 0.8320\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 13s 122ms/step - loss: 0.4709 - sparse_categorical_accuracy: 0.8363 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.8371\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 13s 120ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.8497\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 13s 124ms/step - loss: 0.4152 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.4169 - val_sparse_categorical_accuracy: 0.8490\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 13s 122ms/step - loss: 0.3889 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.3734 - val_sparse_categorical_accuracy: 0.8653\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 13s 118ms/step - loss: 0.3588 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.3483 - val_sparse_categorical_accuracy: 0.8739\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 13s 122ms/step - loss: 0.3345 - sparse_categorical_accuracy: 0.8780 - val_loss: 0.3183 - val_sparse_categorical_accuracy: 0.8855\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 13s 119ms/step - loss: 0.3071 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.2957 - val_sparse_categorical_accuracy: 0.8929\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 13s 121ms/step - loss: 0.2832 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.2651 - val_sparse_categorical_accuracy: 0.9064\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 13s 121ms/step - loss: 0.2619 - sparse_categorical_accuracy: 0.9060 - val_loss: 0.2469 - val_sparse_categorical_accuracy: 0.9121\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 13s 119ms/step - loss: 0.2331 - sparse_categorical_accuracy: 0.9180 - val_loss: 0.2258 - val_sparse_categorical_accuracy: 0.9194\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 13s 124ms/step - loss: 0.2123 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9357\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 13s 119ms/step - loss: 0.1905 - sparse_categorical_accuracy: 0.9353 - val_loss: 0.2032 - val_sparse_categorical_accuracy: 0.9264\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 13s 122ms/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9439 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9442\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 13s 121ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9562 - val_loss: 0.1425 - val_sparse_categorical_accuracy: 0.9526\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89506028e0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=[eng_pad_seq, fr_pad_seq], y=np.expand_dims(fr_pad_seq_noST, axis=-1),\n",
        "          batch_size=1024, epochs=20, validation_split=0.2, workers=2, use_multiprocessing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UoEcxyJztiQ"
      },
      "source": [
        "Define a function that gets an input sentence in english and gives the output sentence in the french language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUU_RdCxYpM6"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "def eng_fr_translation_model1(input):\n",
        "  st_input=remove_punctuation(input)\n",
        "  st_input= 'ST '+st_input.strip().lower()+' EN'\n",
        "  st_input=eng_tokenizer.texts_to_sequences([st_input])\n",
        "  st_input=pad_sequences(st_input, maxlen=max_eng_length+2, padding='post')\n",
        "  \n",
        "  encoder = tf.keras.Model(inputs=E_input, outputs=[Eh, Ec])\n",
        "\n",
        "  Sh_init = Input(shape=(512,))                                          \n",
        "  Sc_init = Input(shape=(512,))                                          \n",
        "  S_input = Input(shape=(1,),)                         \n",
        "  S_embedding  = decoder_embedding(S_input)                                    \n",
        "  S_lstm, Sh, Sc = decoder_lstm(S_embedding , initial_state=[Sh_init, Sc_init]) \n",
        "  S_output = decoder_dense(S_lstm) \n",
        "\n",
        "  sampler = tf.keras.Model(inputs=[S_input, Sh_init, Sc_init], outputs=[S_output, Sh, Sc])\n",
        "\n",
        "  st_h, st_c = encoder.predict(st_input)\n",
        "\n",
        "  st_input = fr_tokenizer.word_index['st']\n",
        "  st_input = np.array([[st_input]])  \n",
        "\n",
        "  prediction_tok = []                     \n",
        "  for i in range(num_fr_words):\n",
        "      probs, st_h, st_c = sampler.predict([st_input, st_h, st_c])\n",
        "      \n",
        "      st_input = probs.argmax(axis=-1)\n",
        "      \n",
        "      token = probs.argmax()\n",
        "      if token != fr_tokenizer.word_index['en']:\n",
        "        prediction_tok.append(token)\n",
        "      \n",
        "      if token == fr_tokenizer.word_index['en']:\n",
        "\n",
        "          break    \n",
        "\n",
        "  words = [fr_tokenizer.index_word[x] for x in prediction_tok if x in fr_tokenizer.index_word]\n",
        "  words=' '.join(words)\n",
        "\n",
        "  return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUQIcAjWz3bt"
      },
      "source": [
        "Test the following sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "fDmNqnZIQMko",
        "outputId": "85b91cfe-c103-4c6e-c0b2-36d4b9ccaf0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 363ms/step\n",
            "1/1 [==============================] - 0s 361ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'elle conduit le nouveau camion blanc'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "eng_fr_translation_model1(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdI2XhaBz6CN"
      },
      "source": [
        "Try to improve your model by modifying the architecture to take into account bidirectionality which is very useful in Machine Translation. Create a new model called model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch28BLsbGnCn"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "E_input_2 = Input(shape=(max_eng_length+2,))                               \n",
        "E_embedding_2 = Embedding(input_dim=num_eng_words, output_dim=50)(E_input_2) \n",
        "_, Eh1_2, Ec1_2, Eh2_2, Ec2_2 = Bidirectional(LSTM(units=512, return_state=True))(E_embedding_2)      \n",
        "Eh_2 = Concatenate()([Eh1_2, Eh2_2])\n",
        "Ec_2 = Concatenate()([Ec1_2, Ec2_2])\n",
        "\n",
        "# Decoder layer definitions\n",
        "decoder_embedding_2 = Embedding(input_dim=num_fr_words, output_dim=50)\n",
        "decoder_lstm_2 = Bidirectional(LSTM(512, return_sequences=True, return_state=True))\n",
        "decoder_dense_2 = Dense(num_fr_words, activation='softmax')\n",
        "\n",
        "# Decoder in train mode\n",
        "D_input_2 = Input(shape=(max_fr_length+2,))                         \n",
        "D_embedding_2 = decoder_embedding_2(D_input_2)                                            \n",
        "D_lstm_2, _, _, _, _ = decoder_lstm_2(D_embedding_2, initial_state=[Eh_2[:, :512], Ec_2[:, :512], Eh_2[:, 512:], Ec_2[:, 512:]])           \n",
        "D_output_2 = decoder_dense_2(D_lstm_2) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDvxt9L0C21"
      },
      "source": [
        "compile and train your new model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK1QvVmaTWI2",
        "outputId": "7bc25660-d437-4b44-fadd-a1f918634aab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_50 (InputLayer)          [(None, 17)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_14 (Embedding)       (None, 17, 50)       10100       ['input_50[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_14 (Bidirectiona  [(None, 1024),      2306048     ['embedding_14[0][0]']           \n",
            " l)                              (None, 512),                                                     \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " input_51 (InputLayer)          [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 1024)         0           ['bidirectional_14[0][1]',       \n",
            "                                                                  'bidirectional_14[0][3]']       \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 1024)         0           ['bidirectional_14[0][2]',       \n",
            "                                                                  'bidirectional_14[0][4]']       \n",
            "                                                                                                  \n",
            " embedding_15 (Embedding)       (None, 23, 50)       17300       ['input_51[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_28 (S  (None, 512)         0           ['concatenate_14[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_29 (S  (None, 512)         0           ['concatenate_15[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_30 (S  (None, 512)         0           ['concatenate_14[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_31 (S  (None, 512)         0           ['concatenate_15[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " bidirectional_15 (Bidirectiona  [(None, 23, 1024),  2306048     ['embedding_15[0][0]',           \n",
            " l)                              (None, 512),                     'tf.__operators__.getitem_28[0][\n",
            "                                 (None, 512),                    0]',                             \n",
            "                                 (None, 512),                     'tf.__operators__.getitem_29[0][\n",
            "                                 (None, 512)]                    0]',                             \n",
            "                                                                  'tf.__operators__.getitem_30[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_31[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 23, 346)      354650      ['bidirectional_15[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,994,146\n",
            "Trainable params: 4,994,146\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "model2 = tf.keras.Model(inputs=[E_input_2, D_input_2], outputs=D_output_2)\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])    \n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRNsurgGucyZ",
        "outputId": "5aaa5240-b147-424f-c6d6-f3570fe42f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "108/108 [==============================] - 36s 263ms/step - loss: 2.4997 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.6689 - val_sparse_categorical_accuracy: 0.6042\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 1.0996 - sparse_categorical_accuracy: 0.7083 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.8075\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 29s 265ms/step - loss: 0.4187 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.1931 - val_sparse_categorical_accuracy: 0.9642\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 28s 256ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9964\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 28s 262ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 29s 265ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 28s 261ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 0.9996\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 28s 259ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 0.9997\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 28s 261ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9998\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 28s 260ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 0.9999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7206d9c190>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.fit(x=[eng_pad_seq, fr_pad_seq], y=np.expand_dims(fr_pad_seq_noST, axis=-1),\n",
        "          batch_size=1028, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkpOI2JI0GBx"
      },
      "source": [
        "Define a new function that relies on your new model to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gulu8OiXTbae"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "def eng_fr_translation_model2(input):\n",
        "  st_input=remove_punctuation(input)\n",
        "  st_input= 'ST '+st_input.strip().lower()+' EN'\n",
        "  st_input=eng_tokenizer.texts_to_sequences([st_input])\n",
        "  st_input=pad_sequences(st_input, maxlen=max_eng_length+2, padding='post')\n",
        "  encoder = tf.keras.Model(inputs=E_input_2, outputs=[Eh1_2, Ec1_2, Eh2_2, Ec2_2])\n",
        "\n",
        "  Sh_init1 = Input(shape=(512,))                                          \n",
        "  Sc_init1 = Input(shape=(512,))    \n",
        "  Sh_init2 = Input(shape=(512,))                                          \n",
        "  Sc_init2 = Input(shape=(512,))                                       \n",
        "  S_input = Input(shape=(1,),)                         \n",
        "  S_embedding  = decoder_embedding_2(S_input)                                    \n",
        "  S_lstm, Sh1_2, Sc1_2, Sh2_2, Sc2_2 = decoder_lstm_2(S_embedding , initial_state=[Sh_init1, Sc_init1, Sh_init2, Sc_init2]) \n",
        "  S_output = decoder_dense_2(S_lstm) \n",
        "\n",
        "  sampler = tf.keras.Model(inputs=[S_input, Sh_init1, Sc_init1, Sh_init2, Sc_init2], outputs=[S_output, Sh1_2, Sc1_2, Sh2_2, Sc2_2])\n",
        "\n",
        "  st_h1, st_c1, st_h2, st_c2 = encoder.predict(st_input)\n",
        "\n",
        "  st_input = fr_tokenizer.word_index['st']\n",
        "  st_input = np.array([[st_input]])  \n",
        "\n",
        "  prediction_tok = []                     \n",
        "  for i in range(num_fr_words):\n",
        "      probs, st_h1, st_c1, st_h2, st_c2 = sampler.predict([st_input, st_h1, st_c1, st_h2, st_c2])\n",
        "      \n",
        "      st_input = probs.argmax(axis=-1)\n",
        "      \n",
        "      token = probs.argmax()\n",
        "      if token != fr_tokenizer.word_index['en']:\n",
        "        prediction_tok.append(token)\n",
        "      \n",
        "      if token == fr_tokenizer.word_index['en']:\n",
        "\n",
        "          break    \n",
        "\n",
        "  words = [fr_tokenizer.index_word[x] for x in prediction_tok if x in fr_tokenizer.index_word]\n",
        "  words=' '.join(words)\n",
        "\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8CO0pO6-UAeE",
        "outputId": "7e0a354b-b7be-4d1f-8bd9-3dcfc402002c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 585ms/step\n",
            "1/1 [==============================] - 1s 604ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'il conduisait cette nouvelle'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "eng_fr_translation_model2(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGeXrjqbZen7"
      },
      "source": [
        "**What is another adjustment in terms of architecture that you might be able to do to improve your model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bekjOkjbZlBf"
      },
      "source": [
        "\n",
        "we can add a RepeatVector and TimeDistributed Layers. RepeatVector repeats the input layer n-times. TimeDistributed applies a layer to every temporal slice of the input. It helps to keep one-to-one relations with input and its corresponding output.\n",
        "We can also add an Attention Layer. Attention models help relate input sequence units disregarding distance between them in space and time, at the same time make sequence data processing more parallelizable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnIN2lD2tn05"
      },
      "source": [
        "**What are some additional ways that we can do to improve the performance of our model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7_MCCbQt3uq"
      },
      "source": [
        "Our dataset includes very limited number of unique words, increasing the training set will get us better results. we can also use data augmentation which increases the diversity of the data and help the model better generalize to unseen data. We could also consider fine-tuning. Additionally, as the bi-lstm, did not perform good, we could try another prediction method or a different neurons or layer number. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
